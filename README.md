# Adversarial Noise Workshop

This workshop about Artificial Intelligence (AI) and its weakness to ‘Adversarial Attacks’ will tackle ways AI vision can be misled by adding visual noise to images, leading to malfunctions in the system. Javier will give an introduction to Adversarial Attacks applied to images and we will explore code examples that implement different adversarial techniques. This workshop will also propose a space for dialogue and discussion around the subject.

The project is subsidized by the Dutch funds *Stimuleringsfonds Creatieve Industrie* for Digital Culture.

The notes are from the workshop [*Adversarial Noise*](https://hsbxl.be/events/adversarial-noise/2021-09-26/) by Javier Lloret Pardo at HSBXL.

If you are unfamiliar with neural networks you can take a look at [teachable machine](https://teachablemachine.withgoogle.com/).

## How to work with this book

To work with the notebooks you can use binder or work locally - a GPU is advised.

## License

The code is licensed with the MIT license.
